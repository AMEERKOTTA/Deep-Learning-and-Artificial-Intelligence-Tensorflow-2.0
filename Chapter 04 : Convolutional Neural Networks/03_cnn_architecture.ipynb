{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrRnqGi8VQMZAlSVoEw2wJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMEERKOTTA/Deep-Learning-and-Artificial-Intelligence-Tensorflow-2.0/blob/main/Chapter%2004%20%3A%20Convolutional%20Neural%20Networks/03_cnn_architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN ARCHITECTURE**\n",
        "\n",
        "+ Modern CNN are Originated from LeNet.\n",
        "+ Typical CNN have 2 stages.\n",
        "    + Stage 1 :- [Conv + Pooling layer]\n",
        "    + Stage 2 :- [Dense Layers]\n",
        "\n",
        "**POOLING LAYER**\n",
        "\n",
        "+ Pooling is Downsampling.\n",
        "+ ie, output a smaller image from a larger image.\n",
        "+ input image = 100x100\n",
        "+ pooling by 2 gives an output image of 50x50.\n",
        "+ 2 kind of Pooling Operations \n",
        "    + MaxPooling.\n",
        "    + Avg Pooling.\n",
        "\n",
        "MAX POOLING : MaxPooling is from the available values taking the Maximum Value to the Downsampled Output.\n",
        "\n",
        "AVG POOLING : Avg Pooling is taking the avg value from the available Values to the Downsampled Output.\n",
        "\n",
        "WHY WE NEED TO USE POOLING\n",
        "\n",
        "+ If we shrink the image, we have less data to process.\n",
        "+ Translational Invariance : I don't care where in the Image the feature occured. I just care that it did.\n",
        "+ Convolution is the Pattern Finder method.\n",
        "+ the highest number is the best matching location.\n",
        "+ Different Pooling Size \n",
        "    + 2x2, 3x3 etc.\n",
        "    + it is also possible for boxes to overlap.\n",
        "    + for the 2x2 filter, if the stride = 2.\n",
        "    + then there will be no overlap.\n",
        "    + if the stride = 1.\n",
        "    + there will be overlap.\n",
        "+ So after Pooling the Input Image will shrink.\n",
        "+ Since the filters stays the same size, they find increasingly large patterns.\n",
        "+ This is why CNNs learns hierarchical features.\n",
        "\n",
        "LOOSING INFORMATION\n",
        "\n",
        "+ do we loose information if we shrink the image.\n",
        "+ we loose spatial information\n",
        "+ we dont care where the features was found.\n",
        "+ we havent yet considered the number of feature maps.\n",
        "+ Generally, these increase at each layer.\n",
        "+ So we gain information in terms of what features were found.\n",
        "\n",
        "\n",
        "HYPERPARAMETERS\n",
        "\n",
        "+ In CNNs, there are more choices.\n",
        "+ with CNNs conventions are pretty standard.\n",
        "+ small filters relative to images.\n",
        "+ 3x3, 5x5, 7x7 etc.\n",
        "+ repeat `conv + pool > conv + pool > conv + pool` etc\n",
        "+ Increase the feature maps.\n",
        "+ like `32 --> 64 --> 128 --> 128 --> 256`\n",
        "\n",
        "\n",
        "ALTERNATIVE TO POOLING : STRIDES\n",
        "\n",
        "+ We can avoid pooling just by doing strided convolutions.\n",
        "+ We get the same Reduction in output Image Size.\n",
        "+ Strides defines how much the filter should move when doing convolution.\n",
        "\n",
        "\n",
        "DENSE NEURAL NETWORKS\n",
        "\n",
        "+ the shape of image is not appropriate for Neural Networks.\n",
        "+ Output of the Convolution : HxWxC (no of feature maps).\n",
        "+ Dense Layer Expects 1D input vector.\n",
        "+ We can make the 1D vector by Flattening.\n",
        "\n",
        "\n",
        "ALTERNATIVE TO FLATTENING - GLOBAL MAX POOLING\n",
        "\n",
        "+ what if we have different sized images.\n",
        "+ Can CNNs handle this situation - Yes,\n",
        "+ Using the Global MaxPooling Layers.\n",
        "+ if we are using Flattening.\n",
        "+ for 32 x 32 image, if we are doing the four conv and pooling.\n",
        "+ `32X32 > 16X16 > 8X8 > 4X4 > 2X2`\n",
        "+ if the output feature map = 100.\n",
        "+ output will be 2x2x100 = 400 D\n",
        "+ and same process for 64X64 image.\n",
        "+ `64X64 > 32X32 > 16X16 > 8X8 > 4X4`\n",
        "+ the output would be, 4x4x100 = 1600 D.\n",
        "\n",
        "+ Neural Networks cannot handle input vectors of Different Sizes.\n",
        "\n",
        "GLOBAL MAX POOLING\n",
        "\n",
        "+ Here we always gets an Output of 1X1XC (or just vector of size C)\n",
        "+ regardless of H and W.\n",
        "+ takes the max over each feature map.\n",
        "+ we dont care where feature found.\n",
        "+ Also, Global Average Pooling.\n"
      ],
      "metadata": {
        "id": "Y2RfslKsomPV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPeQ6QfXoqJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}