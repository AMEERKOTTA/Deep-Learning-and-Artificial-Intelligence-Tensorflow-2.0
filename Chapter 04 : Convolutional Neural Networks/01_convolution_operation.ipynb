{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8SI790rGvl770f5SWcgy6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMEERKOTTA/Deep-Learning-and-Artificial-Intelligence-Tensorflow-2.0/blob/main/Chapter%2004%20%3A%20Convolutional%20Neural%20Networks/01_convolution_operation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHAT IS CONVOLUTION\n",
        "\n",
        "+ Convolution is the Image Modifier.\n",
        "+ Feature Transformation using the Filters.\n",
        "+ Some filters will Blurr the Output Image after Convolution.\n",
        "+ Some filters will find the Edge.\n",
        "+ They can be used as Edge Detectors.\n",
        "\n",
        "PADDING\n",
        "\n",
        "+ the output image will be smaller after doing the convolution operation.\n",
        "+ now if we want the output the same as input.\n",
        "+ then we can use the concept of padding.\n",
        "+ `padding = \"same\"`\n",
        "+ `padding = \"valid\"`\n",
        "+ `padding = \"full\"`\n",
        "\n",
        "| MODE | OUTPUT SIZE | USAGE |\n",
        "|------|-------------|-------|\n",
        "|valid | N - K + 1       | Typical |\n",
        "|same  | N           | Typical |\n",
        "| full | N + K - 1 | Atypical |\n",
        "\n",
        "+ Why do we need to do the Parameter Sharing ?\n",
        "\n",
        "  + Lets say, we used the weights again and again.\n",
        "  + then we could have less parameters.\n",
        "  + use up less RAM, and make the Computation more Efficient.\n",
        "\n",
        "+ MNIST Data :- 28x28 - 784 sized input vector (features).\n",
        "+ CIFAR - 10 :- 32x32x3 - 3072 features.\n",
        "+ VGG (modern CNN) looks at images of [224x224] - 150528 features.\n",
        "+ HD Resolution :- 1280x720 :-- 2.8 million features."
      ],
      "metadata": {
        "id": "jy4P_3nP8vgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## define a function to do convolution on Images with Kernel\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from PIL import Image\n",
        "\n",
        "def convolve_image(image_path, kernel):\n",
        "    # Load the image using PIL\n",
        "    image = Image.open(image_path)\n",
        "    # Convert the image to grayscale\n",
        "    image = image.convert('L')\n",
        "    # Convert the image to a NumPy array\n",
        "    image_array = np.array(image)\n",
        "    # Perform convolution on the image array using the specified kernel\n",
        "    convolved_image = signal.convolve2d(image_array, kernel, mode='same', boundary='symm')\n",
        "    # Convert the convolved image back to a PIL Image object\n",
        "    convolved_image = Image.fromarray(convolved_image)\n",
        "    # Return the convolved image\n",
        "    return convolved_image"
      ],
      "metadata": {
        "id": "l4EPAOkT8zZT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_23GbPP9aJa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}