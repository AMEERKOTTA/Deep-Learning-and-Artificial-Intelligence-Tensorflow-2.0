{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqDHlHsCvIXxAbXCaQCDzu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMEERKOTTA/Deep-Learning-and-Artificial-Intelligence-Tensorflow-2.0/blob/main/Chapter%2005%20%3A%20Transfer%20Learning%20for%20Computer%20Vision/03_training_on_large_datasets_techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING ON LARGE DATASETS AND TECHNIQUES**\n",
        "\n",
        "+ How to work with Large Datasets in Tensorflow and Keras.\n",
        "+ When you first learning about deep learning, it is convenient to have MNIST, CIFAR-10, SVHN etc as CSV files or Numpy array.\n",
        "+ In real world, Images are not CSVs, Images are Images. like JPEG, PNG ...\n",
        "+ Real Images are much Larger than MNIST (28x28) and CIFAR-10 (32x32)\n",
        "+ VGG and ResNet are trained on ImageNet images resized to (224x224).\n",
        "\n",
        "\n",
        "LARGE IMAGE DATASET\n",
        "\n",
        "+ How much space does it take to store 1 million images of size (224x224).\n",
        "+ ie, 1 million images x (224x224x3) bytes/image.\n",
        "+ ~ 150 billion bytes.\n",
        "+ ~ 140 GB.\n",
        "+ that would not fit in a RAM on a Standard Machine.\n",
        "\n",
        "WHAT IS THE SOLUTION ??\n",
        "\n",
        "+ Recognize the Difference between Memory and Disk.\n",
        "+ Disk is Slow, and memory is Fast.\n",
        "+ Model read data from Memory.\n",
        "+ Image files lives on Disk.\n",
        "+ Since we do Gradient Descent, only the current batch needs to exist on the memory.\n",
        "\n",
        "Assume that we have two arrays / lists.\n",
        "\n",
        "  + list of filenames.\n",
        "  + list of labels.\n",
        "\n",
        "Suppose batch_size = 32\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "for i in range(n_labels):\n",
        "    x = load_images(filenames[i:i+32])\n",
        "    y = labels[i:i+32]\n",
        "    model.train_on_batch(x,y)\n",
        "```\n",
        "\n",
        "HOW TO DO IT IN TENSORFLOW AND KERAS\n",
        "\n",
        "The main ingredients needed\n",
        "\n",
        "1. gen = ImageDataGenerator()\n",
        "\n",
        "    + Automatically generates data in Batches.\n",
        "    + Data Augmentation (shifting, rotating, flipping, ...)\n",
        "    + Preprocessing (via preprocess_input)\n",
        "\n",
        "2. generator = gen.flow_from_directory()\n",
        "\n",
        "    + Specify the target image size.\n",
        "    + eg :- resize all images to be (224x224), batchsize.\n",
        "\n",
        "3. model.fit_generator(generator)\n",
        "\n",
        "    + Used in place of `model.fit(x,y)`\n",
        "\n",
        "\n",
        "TWO APPROACHES IN TRANSFER LEARNING\n",
        "\n",
        "1. Use Data Augmentation with ImageDataGenerator.\n",
        "    + ie, entire CNN Computation must be inside the Loop.\n",
        "2. PreCompute the Z without Data Augmentation.\n",
        "    + Only need to train a Logistic Regression on (Z,Y)\n",
        "\n",
        "\n",
        "\n",
        "|          |   with Data Augmentation  |   without Data Augmentation  |\n",
        "|----------|---------------------------|------------------------------|\n",
        "| Speed    | Slow (must pass through entire CNN)  | Fast (only need to pass through one Dense layer) |\n",
        "| Generalization / Accuracy  |  Possibly better for Generalization  |  Possibly Worse for Generalization | \n",
        "\n",
        "***"
      ],
      "metadata": {
        "id": "9cEbyU-mms7B"
      }
    }
  ]
}