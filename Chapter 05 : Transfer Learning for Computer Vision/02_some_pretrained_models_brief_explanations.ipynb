{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdWeN4oBeQZYNveEhr/Q+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMEERKOTTA/Deep-Learning-and-Artificial-Intelligence-Tensorflow-2.0/blob/main/Chapter%2005%20%3A%20Transfer%20Learning%20for%20Computer%20Vision/02_some_pretrained_models_brief_explanations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SOME PRE-TRAINED MODELS**\n",
        "\n",
        "1. *VGG (Visual Geometry Group)*\n",
        "\n",
        "+ Named after the Research Group created it.\n",
        "+ Not different from CNN, just bigger.\n",
        "+ Options :- VGG16 and VGG19.\n",
        "\n",
        "2. *ResNet Model*\n",
        "\n",
        "+ CNN with Branches.\n",
        "+ One branch is Identity Function, so the Other Learns the Residual.\n",
        "+ Variations :-  \n",
        "    + ResNet50\n",
        "    + ResNet101\n",
        "    + ResNet152\n",
        "    + ResNet_v2\n",
        "    + ResNeXt\n",
        "\n",
        "3. *INCEPTION*\n",
        "\n",
        "+ Multiple Convolutions in Parallel Branches.\n",
        "+ Instead of trying the Different filter sizes.\n",
        "+ Just try them all.\n",
        "\n",
        "\n",
        "4. *MOBILE NET*\n",
        "\n",
        "+ LightWeight : Make a trade off between speed and accuracy.\n",
        "+ Meant for less Powerful Machines.\n",
        "+ Like Mobile and Embedded.\n",
        "\n",
        "PREPROCESSING\n",
        "\n",
        "+ Since we are building pre-used CNNs, our data must be formatted just like Original.\n",
        "+ We usually works with RGB pixel values in `[0,1] or [-1,1]`.\n",
        "+ VGG for Example uses BGR with Pixel Values centered but not Scaled.\n",
        "+ Just Import the `preprocess_input` from the same module as your pretrained network.\n",
        "\n",
        "Code Below.\n"
      ],
      "metadata": {
        "id": "JjQarMWb-1i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "## import the pretrained model Resnet 50 and preprocess_input unit.\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "## import the pretrained model Inception v3 and preprocess_input unit.\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "eioW0n4n-7pb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***"
      ],
      "metadata": {
        "id": "ncvW8krHC0Zd"
      }
    }
  ]
}